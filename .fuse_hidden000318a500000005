#!/bin/bash

# PDF to Q&A Dataset Generator Launcher
# 
# Usage Examples:
#   ./run.sh                    # Use default settings (Ollama)
#   AI_PROVIDER=openai ./run.sh # Use OpenAI for this run
#   AI_MODEL=gpt-4 ./run.sh     # Use specific model
#
# Configuration:
#   Edit .env file to set:
#   - AI_PROVIDER (ollama/openai)
#   - AI_MODEL (optional)
#   - OPENAI_API_KEY (for OpenAI)
#   - HUGGING_FACE_HUB_TOKEN (optional)
#   - TRAIN_MODEL (true/false)
#   - BASE_MODEL (for fine-tuning)

set -e

echo "üöÄ Starting PDF to Q&A Dataset Generator..."

# Check if Python is installed
if ! command -v python &> /dev/null; then
    echo "‚ùå Python is not installed. Please install Python 3.8+ first."
    exit 1
fi

# Create virtual environment if it doesn't exist
if [ ! -d ".venv" ]; then
    echo "üì¶ Creating virtual environment..."
    python -m venv .venv
fi

# Activate virtual environment
echo "üîß Activating virtual environment..."
if [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
    source .venv/Scripts/activate
else
    source .venv/bin/activate
fi

# Install dependencies
echo "üì• Installing dependencies..."
pip install -r requirements.txt

# Check if .env exists
if [ ! -f ".env" ]; then
    echo "‚ö†Ô∏è  .env file not found. Please create one with your configuration"
    echo "You can copy from .env.example and update the values."
fi

# Interactive configuration
echo "üìã Configuration Setup"
echo "1. Select AI Provider:"
echo "   1) Ollama (default)"
echo "   2) OpenAI"
read -p "Choose provider (1-2) [1]: " provider_choice
provider_choice=${provider_choice:-1}

if [ "$provider_choice" = "2" ]; then
    AI_PROVIDER="openai"
    echo "Enter OpenAI model (gpt-4o-mini, gpt-3.5-turbo, gpt-4) [gpt-4o-mini]:"
    read -p "Model: " ai_model
    ai_model=${ai_model:-gpt-4o-mini}
else
    AI_PROVIDER="ollama"
    echo "Enter Ollama model [cesarchamal/qa-expert]:"
    read -p "Model: " ai_model
    ai_model=${ai_model:-cesarchamal/qa-expert}
fi

echo "2. Dataset handling:"
echo "   1) Use existing dataset if found (default)"
echo "   2) Always overwrite existing dataset"
read -p "Choose option (1-2) [1]: " dataset_choice
dataset_choice=${dataset_choice:-1}

if [ "$dataset_choice" = "2" ]; then
    OVERWRITE_DATASET="true"
else
    OVERWRITE_DATASET="false"
fi

echo "3. Model training:"
echo "   1) Skip model training (default)"
echo "   2) Train model after dataset creation"
read -p "Choose option (1-2) [1]: " train_choice
train_choice=${train_choice:-1}

if [ "$train_choice" = "2" ]; then
    TRAIN_MODEL="true"
    
    echo "Select fine-tuning method:"
    echo "   1) Full fine-tuning (all parameters, best quality)"
    echo "   2) LoRA fine-tuning (efficient, faster)"
    read -p "Choose method (1-2) [1]: " finetune_method
    finetune_method=${finetune_method:-1}
    
    if [ "$finetune_method" = "2" ]; then
        FINETUNE_METHOD="lora"
    else
        FINETUNE_METHOD="full"
    fi
    
    echo "Select base model:"
    echo "   1) microsoft/DialoGPT-small (fast, lightweight)"
    echo "   2) microsoft/DialoGPT-medium (balanced)"
    echo "   3) microsoft/DialoGPT-large (best quality, slow)"
    echo "   4) distilgpt2 (very fast, basic)"
    echo "   5) gpt2 (standard)"
    echo "   6) Custom model"
    read -p "Choose model (1-6) [1]: " model_choice
    model_choice=${model_choice:-1}
    
    case $model_choice in
        1) base_model="microsoft/DialoGPT-small" ;;
        2) base_model="microsoft/DialoGPT-medium" ;;
        3) base_model="microsoft/DialoGPT-large" ;;
        4) base_model="distilgpt2" ;;
        5) base_model="gpt2" ;;
        6) 
            echo "Enter custom model name:"
            read -p "Model: " base_model
            ;;
        *) base_model="microsoft/DialoGPT-small" ;;
    esac
else
    TRAIN_MODEL="false"
    FINETUNE_METHOD="full"
    base_model="microsoft/DialoGPT-small"
fi

# Update .env file
echo "üìù Updating .env configuration..."
sed -i "s|^AI_PROVIDER=.*|AI_PROVIDER=$AI_PROVIDER|" .env
sed -i "s|^AI_MODEL=.*|AI_MODEL=$ai_model|" .env
sed -i "s|^OVERWRITE_DATASET=.*|OVERWRITE_DATASET=$OVERWRITE_DATASET|" .env
sed -i "s|^TRAIN_MODEL=.*|TRAIN_MODEL=$TRAIN_MODEL|" .env
sed -i "s|^FINETUNE_METHOD=.*|FINETUNE_METHOD=$FINETUNE_METHOD|" .env
sed -i "s|^BASE_MODEL=.*|BASE_MODEL=$base_model|" .env

echo "ü§ñ Using AI provider: $AI_PROVIDER"
echo "üéØ Model: $ai_model"
echo "üìÅ Overwrite dataset: $OVERWRITE_DATASET"
echo "üé® Train model: $TRAIN_MODEL"
if [ "$TRAIN_MODEL" = "true" ]; then
    echo "üõ†Ô∏è Base model: $base_model"
    echo "‚ö° Fine-tuning method: $FINETUNE_METHOD"
fi

# Check if PDF exists
if [ ! -f "jvm_troubleshooting_guide.pdf" ]; then
    echo "‚ö†Ô∏è  PDF file 'jvm_troubleshooting_guide.pdf' not found in current directory"
    echo "Please place your PDF file with this name to continue."
    exit 1
fi

# Check AI provider requirements
if [ "$AI_PROVIDER" = "ollama" ]; then
    echo "üîç Checking Ollama connection..."
    if ! curl -s http://localhost:11434/api/tags > /dev/null; then
        echo "‚ùå Ollama is not running on localhost:11434"
        echo "Please start Ollama first: ollama serve"
        exit 1
    fi
    
    echo "üìã Checking available models..."
    if ! curl -s http://localhost:11434/api/tags | grep -q "cesarchamal/qa-expert"; then
        echo "‚ö†Ô∏è  Model 'cesarchamal/qa-expert' not found. Pulling model..."
        ollama pull cesarchamal/qa-expert
    fi
elif [ "$AI_PROVIDER" = "openai" ]; then
    echo "üîç Checking OpenAI configuration..."
    OPENAI_KEY=$(grep "^OPENAI_API_KEY=" .env 2>/dev/null | cut -d'=' -f2 | tr -d '"')
    if [ -z "$OPENAI_KEY" ] || [ "$OPENAI_KEY" = "your_openai_key_here" ]; then
        echo "‚ùå OpenAI API key not configured in .env file"
        echo "Please set OPENAI_API_KEY in your .env file"
        exit 1
    fi
    echo "‚úÖ OpenAI configuration found"
else
    echo "‚ùå Unsupported AI provider: $AI_PROVIDER"
    echo "Please set AI_PROVIDER to 'ollama' or 'openai' in .env file"
    exit 1
fi

# Pre-download base model if training is enabled
if [ "$TRAIN_MODEL" = "true" ]; then
    echo "üì¶ Pre-downloading base model: $base_model"
    python -c "from transformers import AutoTokenizer, AutoModelForCausalLM; AutoTokenizer.from_pretrained('$base_model'); AutoModelForCausalLM.from_pretrained('$base_model'); print('[SUCCESS] Base model downloaded')"
fi

echo "‚úÖ All checks passed. Starting PDF processing..."
python main.py

echo "üéâ Process completed successfully!"

# Offer to test the model if training was enabled
if [ "$TRAIN_MODEL" = "true" ]; then
    echo ""
    read -p "Do you want to test the trained model? (y/N): " test_model
    if [ "${test_model,,}" = "y" ]; then
        echo "üß™ Starting model testing..."
        python test_model.py
    fi
fi
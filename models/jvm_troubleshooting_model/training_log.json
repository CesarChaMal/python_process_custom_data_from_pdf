[
  {
    "loss": 8.7599,
    "grad_norm": 22.485374450683594,
    "learning_rate": 4.000000000000001e-06,
    "epoch": 0.2,
    "step": 5
  },
  {
    "loss": 7.9604,
    "grad_norm": 10.871452331542969,
    "learning_rate": 9e-06,
    "epoch": 0.4,
    "step": 10
  },
  {
    "loss": 7.4768,
    "grad_norm": 6.954354763031006,
    "learning_rate": 1.4e-05,
    "epoch": 0.6,
    "step": 15
  },
  {
    "loss": 6.3275,
    "grad_norm": 7.248262882232666,
    "learning_rate": 1.9e-05,
    "epoch": 0.8,
    "step": 20
  },
  {
    "loss": 6.0852,
    "grad_norm": 7.275679588317871,
    "learning_rate": 1.923809523809524e-05,
    "epoch": 1.0,
    "step": 25
  },
  {
    "loss": 4.9998,
    "grad_norm": 7.455901622772217,
    "learning_rate": 1.8285714285714288e-05,
    "epoch": 1.2,
    "step": 30
  },
  {
    "loss": 4.5148,
    "grad_norm": 6.9353718757629395,
    "learning_rate": 1.7333333333333336e-05,
    "epoch": 1.4,
    "step": 35
  },
  {
    "loss": 4.0033,
    "grad_norm": 9.821768760681152,
    "learning_rate": 1.6380952380952384e-05,
    "epoch": 1.6,
    "step": 40
  },
  {
    "loss": 3.6869,
    "grad_norm": 5.063451766967773,
    "learning_rate": 1.542857142857143e-05,
    "epoch": 1.8,
    "step": 45
  },
  {
    "loss": 3.6664,
    "grad_norm": 5.6138529777526855,
    "learning_rate": 1.4476190476190478e-05,
    "epoch": 2.0,
    "step": 50
  },
  {
    "loss": 3.3752,
    "grad_norm": 4.972277641296387,
    "learning_rate": 1.3523809523809525e-05,
    "epoch": 2.2,
    "step": 55
  },
  {
    "loss": 3.0743,
    "grad_norm": 5.686460018157959,
    "learning_rate": 1.2571428571428572e-05,
    "epoch": 2.4,
    "step": 60
  },
  {
    "loss": 3.5393,
    "grad_norm": 4.628602504730225,
    "learning_rate": 1.1619047619047621e-05,
    "epoch": 2.6,
    "step": 65
  },
  {
    "loss": 3.3513,
    "grad_norm": 4.499702453613281,
    "learning_rate": 1.0666666666666667e-05,
    "epoch": 2.8,
    "step": 70
  },
  {
    "loss": 3.1962,
    "grad_norm": 3.409532308578491,
    "learning_rate": 9.714285714285715e-06,
    "epoch": 3.0,
    "step": 75
  },
  {
    "loss": 2.7823,
    "grad_norm": 4.696712017059326,
    "learning_rate": 8.761904761904763e-06,
    "epoch": 3.2,
    "step": 80
  },
  {
    "loss": 3.0294,
    "grad_norm": 5.161097526550293,
    "learning_rate": 7.809523809523811e-06,
    "epoch": 3.4,
    "step": 85
  },
  {
    "loss": 2.7953,
    "grad_norm": 6.768136024475098,
    "learning_rate": 6.857142857142858e-06,
    "epoch": 3.6,
    "step": 90
  },
  {
    "loss": 2.7585,
    "grad_norm": 4.358283042907715,
    "learning_rate": 5.904761904761905e-06,
    "epoch": 3.8,
    "step": 95
  },
  {
    "loss": 2.7569,
    "grad_norm": 3.8392956256866455,
    "learning_rate": 4.952380952380953e-06,
    "epoch": 4.0,
    "step": 100
  },
  {
    "loss": 2.763,
    "grad_norm": 4.11355447769165,
    "learning_rate": 4.000000000000001e-06,
    "epoch": 4.2,
    "step": 105
  },
  {
    "loss": 2.6103,
    "grad_norm": 4.060325622558594,
    "learning_rate": 3.047619047619048e-06,
    "epoch": 4.4,
    "step": 110
  },
  {
    "loss": 2.5911,
    "grad_norm": 4.804051876068115,
    "learning_rate": 2.0952380952380955e-06,
    "epoch": 4.6,
    "step": 115
  },
  {
    "loss": 2.432,
    "grad_norm": 3.759310722351074,
    "learning_rate": 1.142857142857143e-06,
    "epoch": 4.8,
    "step": 120
  },
  {
    "loss": 2.6901,
    "grad_norm": 4.170422077178955,
    "learning_rate": 1.904761904761905e-07,
    "epoch": 5.0,
    "step": 125
  },
  {
    "train_runtime": 22742.7086,
    "train_samples_per_second": 0.022,
    "train_steps_per_second": 0.005,
    "total_flos": 1632131481600000.0,
    "train_loss": 4.049055892944336,
    "epoch": 5.0,
    "step": 125
  }
]
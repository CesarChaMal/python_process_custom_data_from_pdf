{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 156,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 11.464587211608887,
      "learning_rate": 4.000000000000001e-06,
      "loss": 9.1054,
      "step": 5
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 8.424354553222656,
      "learning_rate": 9e-06,
      "loss": 8.6007,
      "step": 10
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 6.593825340270996,
      "learning_rate": 1.4e-05,
      "loss": 7.6051,
      "step": 15
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 6.248333930969238,
      "learning_rate": 1.9e-05,
      "loss": 7.0274,
      "step": 20
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 4.949886798858643,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 6.078,
      "step": 25
    },
    {
      "epoch": 1.156862745098039,
      "grad_norm": 4.8982062339782715,
      "learning_rate": 1.8676470588235296e-05,
      "loss": 4.9353,
      "step": 30
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 7.327929496765137,
      "learning_rate": 1.7941176470588237e-05,
      "loss": 4.4254,
      "step": 35
    },
    {
      "epoch": 1.5490196078431373,
      "grad_norm": 5.43156099319458,
      "learning_rate": 1.720588235294118e-05,
      "loss": 4.0348,
      "step": 40
    },
    {
      "epoch": 1.7450980392156863,
      "grad_norm": 6.795039176940918,
      "learning_rate": 1.647058823529412e-05,
      "loss": 3.7095,
      "step": 45
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 4.372946262359619,
      "learning_rate": 1.573529411764706e-05,
      "loss": 3.4728,
      "step": 50
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 4.178189754486084,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 3.1127,
      "step": 55
    },
    {
      "epoch": 2.313725490196078,
      "grad_norm": 3.4378268718719482,
      "learning_rate": 1.4264705882352943e-05,
      "loss": 2.8001,
      "step": 60
    },
    {
      "epoch": 2.5098039215686274,
      "grad_norm": 3.14762282371521,
      "learning_rate": 1.3529411764705885e-05,
      "loss": 2.5765,
      "step": 65
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 4.02496337890625,
      "learning_rate": 1.2794117647058824e-05,
      "loss": 2.85,
      "step": 70
    },
    {
      "epoch": 2.9019607843137254,
      "grad_norm": 3.9552507400512695,
      "learning_rate": 1.2058823529411765e-05,
      "loss": 2.6639,
      "step": 75
    },
    {
      "epoch": 3.0784313725490198,
      "grad_norm": 3.2714200019836426,
      "learning_rate": 1.1323529411764707e-05,
      "loss": 2.6398,
      "step": 80
    },
    {
      "epoch": 3.2745098039215685,
      "grad_norm": 3.608668804168701,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 2.3656,
      "step": 85
    },
    {
      "epoch": 3.4705882352941178,
      "grad_norm": 3.2071421146392822,
      "learning_rate": 9.852941176470589e-06,
      "loss": 2.2963,
      "step": 90
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 3.369004964828491,
      "learning_rate": 9.11764705882353e-06,
      "loss": 2.1067,
      "step": 95
    },
    {
      "epoch": 3.8627450980392157,
      "grad_norm": 3.419358253479004,
      "learning_rate": 8.382352941176472e-06,
      "loss": 2.0901,
      "step": 100
    },
    {
      "epoch": 4.03921568627451,
      "grad_norm": 3.2108864784240723,
      "learning_rate": 7.647058823529411e-06,
      "loss": 2.0612,
      "step": 105
    },
    {
      "epoch": 4.235294117647059,
      "grad_norm": 3.062206983566284,
      "learning_rate": 6.911764705882353e-06,
      "loss": 2.0688,
      "step": 110
    },
    {
      "epoch": 4.431372549019608,
      "grad_norm": 3.1700174808502197,
      "learning_rate": 6.176470588235295e-06,
      "loss": 2.0205,
      "step": 115
    },
    {
      "epoch": 4.627450980392156,
      "grad_norm": 3.180065870285034,
      "learning_rate": 5.441176470588236e-06,
      "loss": 1.953,
      "step": 120
    },
    {
      "epoch": 4.823529411764706,
      "grad_norm": 3.1743462085723877,
      "learning_rate": 4.705882352941177e-06,
      "loss": 1.7312,
      "step": 125
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.200744152069092,
      "learning_rate": 3.970588235294118e-06,
      "loss": 1.9641,
      "step": 130
    },
    {
      "epoch": 5.196078431372549,
      "grad_norm": 3.148557186126709,
      "learning_rate": 3.2352941176470594e-06,
      "loss": 1.8847,
      "step": 135
    },
    {
      "epoch": 5.392156862745098,
      "grad_norm": 2.9431984424591064,
      "learning_rate": 2.5e-06,
      "loss": 1.9226,
      "step": 140
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 3.659403085708618,
      "learning_rate": 1.7647058823529414e-06,
      "loss": 1.7907,
      "step": 145
    },
    {
      "epoch": 5.784313725490196,
      "grad_norm": 2.930025339126587,
      "learning_rate": 1.0294117647058825e-06,
      "loss": 1.7812,
      "step": 150
    },
    {
      "epoch": 5.980392156862745,
      "grad_norm": 3.2731666564941406,
      "learning_rate": 2.9411764705882356e-07,
      "loss": 1.9178,
      "step": 155
    }
  ],
  "logging_steps": 5,
  "max_steps": 156,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 25,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1978143355699200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

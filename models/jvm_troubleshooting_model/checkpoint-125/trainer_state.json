{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 22.485374450683594,
      "learning_rate": 4.000000000000001e-06,
      "loss": 8.7599,
      "step": 5
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.871452331542969,
      "learning_rate": 9e-06,
      "loss": 7.9604,
      "step": 10
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.954354763031006,
      "learning_rate": 1.4e-05,
      "loss": 7.4768,
      "step": 15
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.248262882232666,
      "learning_rate": 1.9e-05,
      "loss": 6.3275,
      "step": 20
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.275679588317871,
      "learning_rate": 1.923809523809524e-05,
      "loss": 6.0852,
      "step": 25
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.455901622772217,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 4.9998,
      "step": 30
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.9353718757629395,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 4.5148,
      "step": 35
    },
    {
      "epoch": 1.6,
      "grad_norm": 9.821768760681152,
      "learning_rate": 1.6380952380952384e-05,
      "loss": 4.0033,
      "step": 40
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.063451766967773,
      "learning_rate": 1.542857142857143e-05,
      "loss": 3.6869,
      "step": 45
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.6138529777526855,
      "learning_rate": 1.4476190476190478e-05,
      "loss": 3.6664,
      "step": 50
    },
    {
      "epoch": 2.2,
      "grad_norm": 4.972277641296387,
      "learning_rate": 1.3523809523809525e-05,
      "loss": 3.3752,
      "step": 55
    },
    {
      "epoch": 2.4,
      "grad_norm": 5.686460018157959,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 3.0743,
      "step": 60
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.628602504730225,
      "learning_rate": 1.1619047619047621e-05,
      "loss": 3.5393,
      "step": 65
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.499702453613281,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 3.3513,
      "step": 70
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.409532308578491,
      "learning_rate": 9.714285714285715e-06,
      "loss": 3.1962,
      "step": 75
    },
    {
      "epoch": 3.2,
      "grad_norm": 4.696712017059326,
      "learning_rate": 8.761904761904763e-06,
      "loss": 2.7823,
      "step": 80
    },
    {
      "epoch": 3.4,
      "grad_norm": 5.161097526550293,
      "learning_rate": 7.809523809523811e-06,
      "loss": 3.0294,
      "step": 85
    },
    {
      "epoch": 3.6,
      "grad_norm": 6.768136024475098,
      "learning_rate": 6.857142857142858e-06,
      "loss": 2.7953,
      "step": 90
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.358283042907715,
      "learning_rate": 5.904761904761905e-06,
      "loss": 2.7585,
      "step": 95
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.8392956256866455,
      "learning_rate": 4.952380952380953e-06,
      "loss": 2.7569,
      "step": 100
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.11355447769165,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.763,
      "step": 105
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.060325622558594,
      "learning_rate": 3.047619047619048e-06,
      "loss": 2.6103,
      "step": 110
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.804051876068115,
      "learning_rate": 2.0952380952380955e-06,
      "loss": 2.5911,
      "step": 115
    },
    {
      "epoch": 4.8,
      "grad_norm": 3.759310722351074,
      "learning_rate": 1.142857142857143e-06,
      "loss": 2.432,
      "step": 120
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.170422077178955,
      "learning_rate": 1.904761904761905e-07,
      "loss": 2.6901,
      "step": 125
    }
  ],
  "logging_steps": 5,
  "max_steps": 125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 25,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1632131481600000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

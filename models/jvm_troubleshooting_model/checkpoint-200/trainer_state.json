{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 10.956442832946777,
      "learning_rate": 2e-05,
      "loss": 8.4858,
      "step": 5
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.161562442779541,
      "learning_rate": 4.5e-05,
      "loss": 6.9312,
      "step": 10
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.0084075927734375,
      "learning_rate": 4.8947368421052635e-05,
      "loss": 5.9262,
      "step": 15
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.7315263748168945,
      "learning_rate": 4.7631578947368424e-05,
      "loss": 4.2748,
      "step": 20
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.47422456741333,
      "learning_rate": 4.6315789473684214e-05,
      "loss": 4.3012,
      "step": 25
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.824884414672852,
      "learning_rate": 4.5e-05,
      "loss": 3.4396,
      "step": 30
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.9033854007720947,
      "learning_rate": 4.368421052631579e-05,
      "loss": 3.1989,
      "step": 35
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.9368832111358643,
      "learning_rate": 4.236842105263158e-05,
      "loss": 2.7494,
      "step": 40
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.1393914222717285,
      "learning_rate": 4.105263157894737e-05,
      "loss": 2.6864,
      "step": 45
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.415661811828613,
      "learning_rate": 3.973684210526316e-05,
      "loss": 2.6124,
      "step": 50
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.73360276222229,
      "learning_rate": 3.842105263157895e-05,
      "loss": 2.2171,
      "step": 55
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.746591329574585,
      "learning_rate": 3.710526315789474e-05,
      "loss": 1.8014,
      "step": 60
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.254658222198486,
      "learning_rate": 3.578947368421053e-05,
      "loss": 2.1304,
      "step": 65
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.573575496673584,
      "learning_rate": 3.447368421052632e-05,
      "loss": 2.1855,
      "step": 70
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.897324323654175,
      "learning_rate": 3.3157894736842106e-05,
      "loss": 2.2346,
      "step": 75
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.8008947372436523,
      "learning_rate": 3.1842105263157895e-05,
      "loss": 1.4436,
      "step": 80
    },
    {
      "epoch": 3.4,
      "grad_norm": 4.016139030456543,
      "learning_rate": 3.0526315789473684e-05,
      "loss": 1.6229,
      "step": 85
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.969965696334839,
      "learning_rate": 2.9210526315789477e-05,
      "loss": 1.418,
      "step": 90
    },
    {
      "epoch": 3.8,
      "grad_norm": 5.886238098144531,
      "learning_rate": 2.7894736842105263e-05,
      "loss": 1.5537,
      "step": 95
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.6127617359161377,
      "learning_rate": 2.6578947368421052e-05,
      "loss": 1.5634,
      "step": 100
    },
    {
      "epoch": 4.2,
      "grad_norm": 3.4828031063079834,
      "learning_rate": 2.5263157894736845e-05,
      "loss": 1.2542,
      "step": 105
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.848480701446533,
      "learning_rate": 2.394736842105263e-05,
      "loss": 1.1904,
      "step": 110
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.68613862991333,
      "learning_rate": 2.2631578947368423e-05,
      "loss": 1.1414,
      "step": 115
    },
    {
      "epoch": 4.8,
      "grad_norm": 3.3484890460968018,
      "learning_rate": 2.1315789473684212e-05,
      "loss": 1.0488,
      "step": 120
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.2562499046325684,
      "learning_rate": 2e-05,
      "loss": 1.189,
      "step": 125
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.3954355716705322,
      "learning_rate": 1.868421052631579e-05,
      "loss": 1.1714,
      "step": 130
    },
    {
      "epoch": 5.4,
      "grad_norm": 3.142723798751831,
      "learning_rate": 1.736842105263158e-05,
      "loss": 1.0767,
      "step": 135
    },
    {
      "epoch": 5.6,
      "grad_norm": 3.1536996364593506,
      "learning_rate": 1.605263157894737e-05,
      "loss": 0.7503,
      "step": 140
    },
    {
      "epoch": 5.8,
      "grad_norm": 4.425689697265625,
      "learning_rate": 1.4736842105263157e-05,
      "loss": 0.915,
      "step": 145
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.462893009185791,
      "learning_rate": 1.3421052631578948e-05,
      "loss": 0.9615,
      "step": 150
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.614558696746826,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 0.7052,
      "step": 155
    },
    {
      "epoch": 6.4,
      "grad_norm": 4.170025825500488,
      "learning_rate": 1.0789473684210526e-05,
      "loss": 0.749,
      "step": 160
    },
    {
      "epoch": 6.6,
      "grad_norm": 5.745268821716309,
      "learning_rate": 9.473684210526317e-06,
      "loss": 0.8244,
      "step": 165
    },
    {
      "epoch": 6.8,
      "grad_norm": 3.122053623199463,
      "learning_rate": 8.157894736842106e-06,
      "loss": 0.7401,
      "step": 170
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.4364213943481445,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.7861,
      "step": 175
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.4127750396728516,
      "learning_rate": 5.526315789473684e-06,
      "loss": 0.6608,
      "step": 180
    },
    {
      "epoch": 7.4,
      "grad_norm": 3.7247321605682373,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.6388,
      "step": 185
    },
    {
      "epoch": 7.6,
      "grad_norm": 2.944915533065796,
      "learning_rate": 2.8947368421052634e-06,
      "loss": 0.534,
      "step": 190
    },
    {
      "epoch": 7.8,
      "grad_norm": 3.2762534618377686,
      "learning_rate": 1.5789473684210528e-06,
      "loss": 0.6637,
      "step": 195
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.4457108974456787,
      "learning_rate": 2.6315789473684213e-07,
      "loss": 0.7862,
      "step": 200
    }
  ],
  "logging_steps": 5,
  "max_steps": 200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 25,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2611410370560000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
